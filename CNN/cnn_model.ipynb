{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d675e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfa3a3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "206a0704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):\n",
    "    # 位相关运算\n",
    "    h, w = X.shape[-2], X.shape[-1]\n",
    "    kh, kw = K.shape[0], K.shape[1]\n",
    "    Y = torch.zeros(h-kh+1, w-kw+1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i+kh, j:j+kh]*K).sum()\n",
    "    \n",
    "    return Y\n",
    "\n",
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size) -> None:\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f4d9490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0.]]),\n",
       " tensor([[ 0.,  0., -2.,  0.,  0.],\n",
       "         [ 0.,  0., -2.,  0.,  0.],\n",
       "         [ 0.,  0., -2.,  0.,  0.],\n",
       "         [ 0.,  0., -2.,  0.,  0.],\n",
       "         [ 0.,  0., -2.,  0.,  0.]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下面y相当于是边缘检查核，是早期的图像特征提取的方法\n",
    "# 但是注意卷积神经网络的核都是训练出来的\n",
    "x = torch.cat([torch.ones((6, 3)), torch.zeros((6, 3))], axis = 1)\n",
    "k = torch.tensor([[-1,1], [-1,1]])\n",
    "\n",
    "y = corr2d(x, k)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b01eb20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:116.1138916015625\n",
      "epoch:1, loss:78.9574203491211\n",
      "epoch:2, loss:53.69102478027344\n",
      "epoch:3, loss:36.509891510009766\n",
      "epoch:4, loss:24.82672119140625\n",
      "epoch:5, loss:16.882171630859375\n",
      "epoch:6, loss:11.479884147644043\n",
      "epoch:7, loss:7.806321144104004\n",
      "epoch:8, loss:5.308300495147705\n",
      "epoch:9, loss:3.6096436977386475\n"
     ]
    }
   ],
   "source": [
    "# train 得到上面的k\n",
    "net = Conv2D((2,2))\n",
    "lr = 0.02\n",
    "\n",
    "for i in range(10):\n",
    "    y_hat = net(x)\n",
    "    l = (y-y_hat)**2\n",
    "    net.zero_grad()\n",
    "    l.sum().backward()\n",
    "    net.weight.data[:] -= lr*net.weight.grad\n",
    "\n",
    "    print('epoch:{}, loss:{}'.format(i, l.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9a95fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.6748,  0.6303],\n",
       "        [-0.7964,  1.1660]], requires_grad=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4f95585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 填充与步幅\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 3), stride=2, padding=1)\n",
    "x = torch.randn((1 ,1, 5, 5))\n",
    "\n",
    "conv2d(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22d3863e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.3358,  0.3331,  0.3331,  0.3109],\n",
       "           [ 0.3358,  0.3331,  0.3331,  2.0902],\n",
       "           [ 1.1293,  1.1293,  0.7845,  2.0902],\n",
       "           [ 1.1293,  1.1293,  0.7845, -0.5532]]]]),\n",
       " tensor([[[[-0.2446, -0.2797, -0.5868, -0.8199],\n",
       "           [-0.1363, -0.3465, -0.6522,  0.0318],\n",
       "           [ 0.5937,  0.3223, -0.1649, -0.0622],\n",
       "           [ 0.6217,  0.1743, -0.5181, -1.0981]]]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 汇聚层\n",
    "maxpool = nn.MaxPool2d((2,2), stride=1, padding=0)\n",
    "avgpool = nn.AvgPool2d((2,2), stride=1, padding=0)\n",
    "maxpool(x), avgpool(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0318],\n",
       "          [0.5937, 0.3223, 0.0000, 0.0000],\n",
       "          [0.6217, 0.1743, 0.0000, 0.0000]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu = nn.ReLU()\n",
    "relu(avgpool(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e477744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# 定义net来train FashionMNIST\n",
    "mnist_train = torchvision.datasets.FashionMNIST(\n",
    "    root='../data', train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "mnist_test = torchvision.datasets.FashionMNIST(\n",
    "    root='../data', train=False, transform=transforms.ToTensor(), download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00647817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train.data.shape, mnist_train.targets.shape\n",
    "max(mnist_train.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3cfd29e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnNet(nn.Module):\n",
    "    def __init__(self, input_channels=1) -> None:\n",
    "        super().__init__()\n",
    "        self.is_training = True\n",
    "        self.drop_layer = nn.Dropout(0.5)\n",
    "        self.conn2d1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conn2d2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=(5,5), stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conn2d3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=(5,5), stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conn2d4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(2,2), stride=1, padding=1),\n",
    "            # nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # self.conv1 = nn.Conv2d(1, 6, kernel_size=(3,3), stride=1, padding=1)\n",
    "        # self.maxpool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "        # self.conv2 = nn.Conv2d(6, 16, kernel_size=(3,3), stride=1, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.line1 = nn.Sequential(\n",
    "        #     nn.Linear(784, 120),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(120, 84),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(84, 10)\n",
    "        # )\n",
    "        self.line1 = nn.Linear(1152, 256)\n",
    "        self.line2 = nn.Linear(256, 10)\n",
    "        # self.line1 = nn.Linear(1152, 240)\n",
    "        # self.line2 = nn.Linear(240, 84)\n",
    "        # self.line3 = nn.Linear(84, 10)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # c1 = self.conv1(x)\n",
    "        # c1 = self.relu(self.maxpool(c1))\n",
    "        # c2 = self.conv2(c1)\n",
    "        # c2 = self.relu(self.maxpool(c2))\n",
    "        c1 = self.conn2d1(x)\n",
    "        c2 = self.conn2d2(c1)\n",
    "        c3 = self.conn2d3(c2)\n",
    "        c4 = self.conn2d4(c3)\n",
    "        o1 = self.flatten(c4)\n",
    "        # return o1\n",
    "        # l = self.line(o1)\n",
    "        l1 = self.relu(self.line1(o1))\n",
    "        if self.is_training:\n",
    "            l1 = self.drop_layer(l1)\n",
    "        \n",
    "        # l2 = self.relu(self.line2(l1))\n",
    "        # if self.is_training:\n",
    "        #     l2 = self.drop_layer(l2)\n",
    "        # l3 = self.line3(l2)\n",
    "        o = self.line2(l1)\n",
    "        return o\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.is_training = False\n",
    "        o = self.forward(x)\n",
    "        self.is_training = True\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1d1e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alexNet\n",
    "class CnnNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.is_training = True\n",
    "        self.drop_layer = nn.Dropout(0.5)\n",
    "        self.conn2d1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, kernel_size=(3,3), stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conn2d2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, kernel_size=(5,5), stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conn2d3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 1024, kernel_size=(5,5), stride=1, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=2),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conn2d4 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 1024, kernel_size=(2,2), stride=1, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.line1 = nn.Linear(9216, 4080)\n",
    "        self.line2 = nn.Linear(4080, 10)\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        c1 = self.conn2d1(x)\n",
    "        c2 = self.conn2d2(c1)\n",
    "        c3 = self.conn2d3(c2)\n",
    "        c4 = self.conn2d4(c3)\n",
    "        o1 = self.flatten(c4)\n",
    "        # return o1\n",
    "        l1 = self.relu(self.line1(o1))\n",
    "        if self.is_training:\n",
    "            l1 = self.drop_layer(l1)\n",
    "        o = self.line2(l1)\n",
    "        return o\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.is_training = False\n",
    "        o = self.forward(x)\n",
    "        self.is_training = True\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a513b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CnnNet                                   [1, 10]                   --\n",
       "├─Sequential: 1-1                        [1, 96, 14, 14]           --\n",
       "│    └─Conv2d: 2-1                       [1, 96, 28, 28]           960\n",
       "│    └─MaxPool2d: 2-2                    [1, 96, 14, 14]           --\n",
       "│    └─BatchNorm2d: 2-3                  [1, 96, 14, 14]           192\n",
       "│    └─ReLU: 2-4                         [1, 96, 14, 14]           --\n",
       "├─Sequential: 1-2                        [1, 256, 6, 6]            --\n",
       "│    └─Conv2d: 2-5                       [1, 256, 12, 12]          614,656\n",
       "│    └─MaxPool2d: 2-6                    [1, 256, 6, 6]            --\n",
       "│    └─BatchNorm2d: 2-7                  [1, 256, 6, 6]            512\n",
       "│    └─ReLU: 2-8                         [1, 256, 6, 6]            --\n",
       "├─Sequential: 1-3                        [1, 1024, 2, 2]           --\n",
       "│    └─Conv2d: 2-9                       [1, 1024, 4, 4]           6,554,624\n",
       "│    └─MaxPool2d: 2-10                   [1, 1024, 2, 2]           --\n",
       "│    └─BatchNorm2d: 2-11                 [1, 1024, 2, 2]           2,048\n",
       "│    └─ReLU: 2-12                        [1, 1024, 2, 2]           --\n",
       "├─Sequential: 1-4                        [1, 1024, 3, 3]           --\n",
       "│    └─Conv2d: 2-13                      [1, 1024, 3, 3]           4,195,328\n",
       "│    └─BatchNorm2d: 2-14                 [1, 1024, 3, 3]           2,048\n",
       "│    └─ReLU: 2-15                        [1, 1024, 3, 3]           --\n",
       "├─Flatten: 1-5                           [1, 9216]                 --\n",
       "├─Linear: 1-6                            [1, 4080]                 37,605,360\n",
       "├─ReLU: 1-7                              [1, 4080]                 --\n",
       "├─Dropout: 1-8                           [1, 4080]                 --\n",
       "├─Linear: 1-9                            [1, 10]                   40,810\n",
       "==========================================================================================\n",
       "Total params: 49,016,538\n",
       "Trainable params: 49,016,538\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 269.55\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 1.47\n",
       "Params size (MB): 196.07\n",
       "Estimated Total Size (MB): 197.53\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "net = CnnNet()\n",
    "summary(net, input_size=(1,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "246337a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "def ac(data_iter, net, device):\n",
    "    num_acs = []\n",
    "    for x, y in data_iter:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_hat = net.predict(x)\n",
    "        maxs, indexs = torch.max(y_hat, dim=1)\n",
    "        num_acs.append(y.eq(indexs).sum()/indexs.shape[0])\n",
    "    return sum(num_acs)/len(num_acs)\n",
    "\n",
    "batch_size = 1024\n",
    "num_epochs = 10\n",
    "lr = 0.1\n",
    "\n",
    "train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_iter = data.DataLoader(mnist_test, batch_size,shuffle=True, num_workers=4)\n",
    "\n",
    "net = CnnNet()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net.to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d68972e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8501, device='cuda:0')\n",
      "tensor(0.3665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8668, device='cuda:0')\n",
      "tensor(0.2419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8850, device='cuda:0')\n",
      "tensor(0.1940, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8838, device='cuda:0')\n",
      "tensor(0.1536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9118, device='cuda:0')\n",
      "tensor(0.1558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9051, device='cuda:0')\n",
      "tensor(0.1687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8950, device='cuda:0')\n",
      "tensor(0.1154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9192, device='cuda:0')\n",
      "tensor(0.1137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9167, device='cuda:0')\n",
      "tensor(0.0946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9094, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    for x,y in train_iter:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_hat = net(x)\n",
    "        l = loss(y_hat, y)\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    print(l)\n",
    "    print(ac(test_iter, net, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b8c2c92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheng\\AppData\\Local\\Temp\\ipykernel_10468\\3493962570.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  o = torch.tensor(mnist_test.data[1,:,:].reshape(1,1,28,28).cuda(), dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[2.7844e-06, 1.1906e-07, 9.9640e-01, 5.5539e-06, 2.1888e-03, 7.1823e-06,\n",
       "          1.3271e-03, 7.3079e-06, 5.9558e-05, 1.0692e-06]], device='cuda:0',\n",
       "        grad_fn=<SoftmaxBackward0>),\n",
       " tensor(2))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = torch.tensor(mnist_test.data[1,:,:].reshape(1,1,28,28).cuda(), dtype=torch.float32)\n",
    "torch.softmax(net(o), dim=1), mnist_test.targets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a653e338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1708c1cc460>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(o.reshape(28,28).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7059998a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
