{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import d2l.torch as d2l\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1460, 331])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './kaggle_house_data/house-prices-advanced-regression-techniques/train.csv'\n",
    "all_features = pd.read_csv(path)\n",
    "label = all_features['SalePrice']\n",
    "all_features = all_features.iloc[:,1:-1]\n",
    "\n",
    "# 若无法获得测试数据，则可根据训练数据计算均值和标准差\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "# 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)\n",
    "all_features = pd.get_dummies(all_features, dummy_na=True)\n",
    "# print(all_features.columns.values)\n",
    "\n",
    "all_features = torch.tensor(all_features.to_numpy(dtype=np.float32), dtype=torch.float32)\n",
    "label = torch.tensor(label.values, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "all_features, label = all_features.cuda(), label.cuda()\n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils import data\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_input, num_output) -> None:\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(num_input, num_output)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        o = self.layer1(x)\n",
    "\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (layer1): Linear(in_features=331, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.01\n",
    "batch_size = 24\n",
    "\n",
    "train_set = data.TensorDataset(all_features, label)\n",
    "train_iter = data.DataLoader(train_set, batch_size, shuffle=True, num_workers=4)\n",
    "net = Net(331, 1).cuda()\n",
    "loss = nn.MSELoss(reduction='none')\n",
    "updater = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "def init_weights(m):\n",
    "        if type == nn.Linear:\n",
    "            nn.init.normal_(m.weight, std=0.01)\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_rmse(net, features, labels):\n",
    "    # 为了在取对数时进一步稳定该值，将小于1的值设置为1\n",
    "    clipped_preds = torch.clip(net(features), 1, float('inf'))\n",
    "    return torch.sqrt(2 * loss(torch.log(clipped_preds), torch.log(labels)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17.0140, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "tensor(16.8088, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "tensor(16.2238, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "tensor(15.8168, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "tensor(15.5040, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "tensor(15.2417, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "tensor(15.0219, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "tensor(14.8338, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "tensor(14.6657, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "tensor(14.5178, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "tensor(14.3814, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "tensor(14.2572, device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "tensor(14.1449, device='cuda:0', grad_fn=<SqrtBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\cheng\\Desktop\\d2l\\多层感知机\\kaggle_house.ipynb 单元格 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cheng/Desktop/d2l/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/kaggle_house.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m epoch \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cheng/Desktop/d2l/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/kaggle_house.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/cheng/Desktop/d2l/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/kaggle_house.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m x,y \u001b[39min\u001b[39;00m train_iter:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cheng/Desktop/d2l/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/kaggle_house.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         updater\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cheng/Desktop/d2l/%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA/kaggle_house.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         l \u001b[39m=\u001b[39m loss(net(x), y)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[0;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\multiprocessing\\queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[0;32m    106\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[1;32m--> 107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[0;32m    108\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m    109\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\multiprocessing\\connection.py:330\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_got_empty_message \u001b[39mor\u001b[39;00m\n\u001b[0;32m    328\u001b[0m             _winapi\u001b[39m.\u001b[39mPeekNamedPipe(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m    329\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(wait([\u001b[39mself\u001b[39;49m], timeout))\n",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\multiprocessing\\connection.py:879\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    876\u001b[0m                 ready_objects\u001b[39m.\u001b[39madd(o)\n\u001b[0;32m    877\u001b[0m                 timeout \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 879\u001b[0m     ready_handles \u001b[39m=\u001b[39m _exhaustive_wait(waithandle_to_obj\u001b[39m.\u001b[39;49mkeys(), timeout)\n\u001b[0;32m    880\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     \u001b[39m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    882\u001b[0m     \u001b[39mfor\u001b[39;00m ov \u001b[39min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mc:\\Program Files\\Python38\\lib\\multiprocessing\\connection.py:811\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    809\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[0;32m    810\u001b[0m \u001b[39mwhile\u001b[39;00m L:\n\u001b[1;32m--> 811\u001b[0m     res \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mWaitForMultipleObjects(L, \u001b[39mFalse\u001b[39;49;00m, timeout)\n\u001b[0;32m    812\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    813\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch = 50\n",
    "for i in range(epoch):\n",
    "    for x,y in train_iter:\n",
    "        updater.zero_grad()\n",
    "        l = loss(net(x), y)\n",
    "        l.sum().backward()\n",
    "        updater.step()\n",
    "    print(log_rmse(net, all_features, label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load('./net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([222393.3438], device='cuda:0', grad_fn=<AddBackward0>) tensor([208500.], device='cuda:0')\n",
      "tensor([184124.0312], device='cuda:0', grad_fn=<AddBackward0>) tensor([181500.], device='cuda:0')\n",
      "tensor([231334.9062], device='cuda:0', grad_fn=<AddBackward0>) tensor([223500.], device='cuda:0')\n",
      "tensor([176943.7500], device='cuda:0', grad_fn=<AddBackward0>) tensor([140000.], device='cuda:0')\n",
      "tensor([287953.5312], device='cuda:0', grad_fn=<AddBackward0>) tensor([250000.], device='cuda:0')\n",
      "tensor([172592.], device='cuda:0', grad_fn=<AddBackward0>) tensor([143000.], device='cuda:0')\n",
      "tensor([266915.], device='cuda:0', grad_fn=<AddBackward0>) tensor([307000.], device='cuda:0')\n",
      "tensor([228467.2812], device='cuda:0', grad_fn=<AddBackward0>) tensor([200000.], device='cuda:0')\n",
      "tensor([133980.2500], device='cuda:0', grad_fn=<AddBackward0>) tensor([129900.], device='cuda:0')\n",
      "tensor([92646.1172], device='cuda:0', grad_fn=<AddBackward0>) tensor([118000.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(net(all_features[i,:]), label[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
